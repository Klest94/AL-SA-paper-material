{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['original-data', 'processed-data']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "RANDSEED = 0\n",
    "\n",
    "root_folder = os.getcwd()\n",
    "data_folder = os.path.join(root_folder, \"datasets\")\n",
    "\n",
    "dnames = os.listdir(data_folder)\n",
    "testing_dnames = dnames[:2]\n",
    "\n",
    "N_TRAIN = 20\n",
    "\n",
    "N_FOLDS = 2\n",
    "testing_dnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([37, 81, 46, 39, 65, 58, 12, 92, 88, 70, 87, 36, 21, 83, 9, 100, 67,\n",
      "            64, 47, 44],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "for data in testing_dnames:\n",
    "\n",
    "    data_file = os.path.join(data_folder, data) #so far correct: reaches the single dataset folder with all the .csv files\n",
    "    \n",
    "    for i in range(N_FOLDS):\n",
    "        X_train = pd.read_csv(os.path.join(data_file, \"X_new_train\"+str(i+1)+\".csv\"))\n",
    "        y_train = pd.read_csv(os.path.join(data_file, \"y_new_train\"+str(i+1)+\".csv\"))\n",
    "        X_test = pd.read_csv(os.path.join(data_file, \"X_new_test\"+str(i+1)+\".csv\"))\n",
    "        y_test = pd.read_csv(os.path.join(data_file, \"y_new_test\"+str(i+1)+\".csv\"))\n",
    "\n",
    "        if y_train.shape[1] == 2: #survival case\n",
    "            \n",
    "            y_train[y_train.columns[-2]] = y_train[y_train.columns[-2]].astype('bool') # needed for correct recarray\n",
    "            y_test[y_test.columns[-2]] = y_test[y_test.columns[-2]].astype('bool') # needed for correct recarray\n",
    "            y_train = y_train.to_records(index=False) #builds the structured array, needed for RSF\n",
    "            y_test = y_test.to_records(index=False) #builds the structured array, needed for RSF\n",
    "\n",
    "\n",
    "# Prepare to (partially mask) all train instances except for the first N_TRAIN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_pool, y_train, y_pool = train_test_split(X_train, y_train, train_size=N_TRAIN, random_state=0)\n",
    "print(X_train.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(False,  3.        ) ( True, 27.        ) (False,  4.        )\n",
      " ( True, 41.        ) ( True, 26.        ) (False,  0.25      )\n",
      " (False,  0.5       ) ( True, 25.        ) ( True, 34.        )\n",
      " (False,  0.75      ) ( True, 33.        ) (False, 15.        )\n",
      " ( True, 34.        ) ( True, 36.        ) ( True, 57.        )\n",
      " ( True, 49.        ) ( True, 31.        ) ( True, 25.        )\n",
      " ( True, 23.        ) ( True, 12.        ) ( True, 17.        )\n",
      " (False,  0.75      ) (False,  7.        ) ( True, 33.        )\n",
      " (False,  0.5       ) ( True, 25.        ) (False, 40.        )\n",
      " (False,  2.        ) ( True, 29.        ) (False, 10.        )\n",
      " (False,  0.5       ) (False,  2.96475681) ( True, 12.        )\n",
      " ( True, 46.        ) (False, 20.        ) ( True, 53.        )\n",
      " ( True, 34.        ) ( True, 38.        ) ( True, 15.        )\n",
      " ( True, 33.        ) (False,  0.75      ) ( True, 36.        )\n",
      " ( True, 16.        ) ( True, 31.        ) (False, 21.        )\n",
      " ( True, 21.        ) ( True, 41.        ) ( True, 26.        )\n",
      " ( True, 36.        ) (False,  0.75      ) ( True, 19.        )\n",
      " ( True, 25.        ) ( True, 55.        ) (False,  0.5       )\n",
      " ( True, 10.        ) (False,  1.        ) ( True, 10.        )\n",
      " ( True, 31.        ) (False, 19.5       ) (False,  3.        )\n",
      " ( True, 12.        ) ( True, 16.        ) ( True, 49.        )\n",
      " (False,  7.5       ) ( True, 40.        ) ( True, 13.        )\n",
      " (False,  1.25      ) ( True, 44.        ) ( True, 32.        )\n",
      " ( True, 32.        ) (False,  1.        ) ( True, 16.        )\n",
      " ( True, 19.        ) (False,  0.25      ) ( True, 29.        )\n",
      " ( True, 52.        ) ( True, 36.        ) ( True, 27.        )\n",
      " ( True, 38.        ) ( True, 35.        ) ( True, 33.        )\n",
      " (False,  1.        ) (False,  1.        ) ( True,  9.        )]\n",
      "==================================================\n",
      "[(False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)\n",
      " (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.) (False, 0.)]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def additional_censoring(y_pool, amount_masking=1, intensity=1, random_state=None):\n",
    "\n",
    "    ''' \n",
    "    - y_pool: np.recarray, it's the pool dataset for active learning querying, part of it\n",
    "        ( or all of it) might be masked ( partially or fully masked)\n",
    "    - amount_masking:\n",
    "        - if float, or == 1 -> probability of masking instances from y_pool. amount_masking=1 -> all instances are masked\n",
    "        - if int > 1 -> total quantity of masked elements in the dataframe, has to be less than np.shape(y_pool)[0]  \n",
    "\n",
    "    - intensity: amount of the 'information loss' due to masking\n",
    "            - if (float, int) -> information loss is contant acorss masked instances, given an instance\n",
    "            with observed values (T_i, \\delta) the new label will be (T_i*(1-intensity), 0)\n",
    "            - if (list, tuple) -> needs to be of the form (e1, e2), length 2. The information loss \n",
    "            in this case is not constant but we have intensity ~ Uniform(e1, e2) instead.  \n",
    "\n",
    "    -random_state: for deterministic generation, good for debugging\n",
    "    '''\n",
    "    \n",
    "    import random\n",
    "    import copy\n",
    "    random.seed(a=random_state) #overrides random seed within random library\n",
    "    np.random.seed(random_state) #overrides random seed in numpy library\n",
    "\n",
    "    assert isinstance(y_pool, np.recarray)\n",
    "\n",
    "    N = y_pool.shape[0]\n",
    "\n",
    "    if amount_masking <= 1 and amount_masking > 0:\n",
    "        mask_vector = np.random.rand(N, ) < amount_masking #>= amount_masking #False if still visible, True if masked\n",
    "    elif isinstance(amount_masking, int) and amount_masking > 1 and amount_masking <= N:\n",
    "        mask_vector = np.array([i in random.sample(range(N), amount_masking) for i in range(N)])\n",
    "    else:\n",
    "        raise KeyError(\"amount_masking is not a float or int in the expected range\")\n",
    "\n",
    "    # checking validity of intensity input. \n",
    "    # TODO: distributons with parameters should be accepted as inputs\n",
    "    if isinstance(intensity, (float, int)):\n",
    "        intens_censoring = np.ones(N)*intensity # censor everything (with fixed intensity)\n",
    "    \n",
    "    elif isinstance(intensity, (tuple, list)):\n",
    "        if len(intensity) != 2:\n",
    "            raise KeyError(\"Intensity variable is a tuple/list of \\\n",
    "                           length: {:d}, expected 2 instead\".format(len(intensity)))\n",
    "        else:\n",
    "            intens_censoring = np.random.uniform(intensity[0], intensity[1], N) #vector with entries in [0, intensity)\n",
    "\n",
    "    # censor_intervals = intens_censoring*y_pool[\"Survival\"] #not robust to name choice, TODO: improve \n",
    "\n",
    "    y_pool2 = copy.copy(y_pool) \n",
    "    y_pool2[\"Survival\"] = y_pool[\"Survival\"]*(1-intens_censoring*(mask_vector))\n",
    "    y_pool2[\"Status\"] = y_pool[\"Status\"]*(1-mask_vector) # sets to False all masked observations\n",
    "\n",
    "    print(y_pool)\n",
    "    print(\"=\"*50)\n",
    "    print(y_pool2)\n",
    "    print(mask_vector)\n",
    "\n",
    "    return y_pool2, intens_censoring\n",
    "\n",
    "\n",
    "y_pool2, intens_censoring = additional_censoring(y_pool, amount_masking=1,\n",
    "                                                 intensity=1,\n",
    "                                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age  pericardialeffusion  fractionalshortening  epss      lvdd  \\\n",
      "26  64.063229                  0.0              0.203306  12.0  4.937163   \n",
      "61  62.000000                  0.0              0.220000  12.1  3.920000   \n",
      "2   58.000000                  0.0              0.170000  28.9  6.730000   \n",
      "\n",
      "    wallmotion-score  wallmotion-index   mult     group  \n",
      "26              6.00              3.00  0.140  2.000000  \n",
      "61             11.00              1.00  0.785  1.783385  \n",
      "2              26.08              2.01  0.928  2.000000  \n",
      "[(False,  3.) ( True, 27.) (False,  4.)]\n",
      "==============================\n",
      "age                     62.000000\n",
      "pericardialeffusion      0.000000\n",
      "fractionalshortening     0.220000\n",
      "epss                    12.100000\n",
      "lvdd                     3.920000\n",
      "wallmotion-score        11.000000\n",
      "wallmotion-index         1.000000\n",
      "mult                     0.785000\n",
      "group                    1.783385\n",
      "Name: 61, dtype: float64\n",
      "61\n",
      "(True, 27.)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(a=None)\n",
    "print(X_pool[:3])\n",
    "print(y_pool[:3])\n",
    "print(\"=\"*30)\n",
    "\n",
    "query_index = random.choice(list(range(X_pool[:3].shape[0])))\n",
    "print(X_pool.iloc[query_index])\n",
    "\n",
    "idx = X_pool.iloc[query_index].name\n",
    "print(idx)\n",
    "print(y_pool[query_index])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure:\n",
    "\n",
    "`X_train` starts with $N$ (N=10?) samples, and new samples from `X_pool` will be queried one at the time.\n",
    "The model is retrained at each iteration.\n",
    "Every $M$ (M=5?) samples, we report performance and learning curve.\n",
    "\n",
    "### Initial set-up:\n",
    "\n",
    "Labels in the `X_pool` are fully censored and no information is available to the model in the beginning.\n",
    "Once the model is queried, the originally masked label $(T, \\delta)$ will be revealed and added to the `X_train` batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  pericardialeffusion  fractionalshortening       epss      lvdd  \\\n",
      "0  66.0                  0.0                  0.29  15.600000  6.150000   \n",
      "1  70.0                  1.0                  0.27   4.700000  4.490000   \n",
      "2  58.0                  0.0                  0.17  28.900000  6.730000   \n",
      "3  61.0                  1.0                  0.27  12.077119  4.850156   \n",
      "4  78.0                  0.0                  0.06  16.100000  5.620000   \n",
      "\n",
      "   wallmotion-score  wallmotion-index   mult  group  \n",
      "0             14.00             1.000  1.000    2.0  \n",
      "1             22.00             2.000  0.786    2.0  \n",
      "2             26.08             2.010  0.928    2.0  \n",
      "3              9.00             1.500  0.428    2.0  \n",
      "4             13.67             1.367  0.714    2.0  \n",
      "<bound method NDFrame.head of           age  pericardialeffusion  fractionalshortening       epss      lvdd  \\\n",
      "0   66.000000                  0.0              0.290000  15.600000  6.150000   \n",
      "2   58.000000                  0.0              0.170000  28.900000  6.730000   \n",
      "3   61.000000                  1.0              0.270000  12.077119  4.850156   \n",
      "4   78.000000                  0.0              0.060000  16.100000  5.620000   \n",
      "5   59.000000                  1.0              0.400000   9.200000  5.360000   \n",
      "6   74.000000                  0.0              0.200000   4.800000  4.560000   \n",
      "7   60.000000                  0.0              0.253000  12.062000  4.603000   \n",
      "8   58.000000                  0.0              0.300000   9.400000  3.490000   \n",
      "9   62.399151                  0.0              0.230000  19.100000  5.490000   \n",
      "10  64.000000                  0.0              0.240000  12.900000  4.720000   \n",
      "11  62.000000                  0.0              0.260000   7.600000  4.420000   \n",
      "12  66.000000                  0.0              0.240000  13.600000  4.380000   \n",
      "13  55.000000                  1.0              0.210000   4.200000  4.160000   \n",
      "14  63.000000                  1.0              0.220384  11.250508  5.310000   \n",
      "15  50.000000                  0.0              0.060000  30.100000  5.950000   \n",
      "16  62.529000                  1.0              0.070000  20.000000  5.200000   \n",
      "17  69.000000                  0.0              0.200000   7.000000  5.050000   \n",
      "18  54.000000                  0.0              0.430000   9.300000  4.790000   \n",
      "19  63.000000                  1.0              0.163042  19.258279  5.193022   \n",
      "\n",
      "    wallmotion-score  wallmotion-index   mult     group  \n",
      "0              14.00             1.000  1.000  2.000000  \n",
      "2              26.08             2.010  0.928  2.000000  \n",
      "3               9.00             1.500  0.428  2.000000  \n",
      "4              13.67             1.367  0.714  2.000000  \n",
      "5              12.00             1.000  0.857  1.783667  \n",
      "6              12.50             1.040  0.857  2.000000  \n",
      "7              16.00             1.450  0.788  1.000000  \n",
      "8              14.00             1.000  1.000  2.000000  \n",
      "9              12.00             1.200  0.710  1.784471  \n",
      "10             12.00             1.000  0.857  1.770480  \n",
      "11             14.00             1.000  1.000  2.000000  \n",
      "12             22.00             2.200  0.714  1.767879  \n",
      "13             14.00             1.560  0.640  2.000000  \n",
      "14              5.00             1.000  0.357  2.000000  \n",
      "15             21.50             2.390  0.643  2.000000  \n",
      "16             24.00             2.000  0.857  1.000000  \n",
      "17             14.50             1.210  0.857  1.780406  \n",
      "18             10.00             1.000  0.714  1.793652  \n",
      "19             23.00             2.300  0.714  2.000000  >\n"
     ]
    }
   ],
   "source": [
    "# X_drop = X_train.loc[1,:]\n",
    "# print(X_train.head(5))\n",
    "# # print(X_drop.name)\n",
    "# # print(X_drop.loc[1])\n",
    "# # print(X_train.head(5))\n",
    "# X_train.drop([X_drop.name], axis=0, inplace=True)\n",
    "# print(X_train.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model = \n",
    "\n",
    "from typing import Optional, Union\n",
    "import random\n",
    "\n",
    "class SamplingQuery:\n",
    "\n",
    "    RANDSEED = 0\n",
    "    import random\n",
    "\n",
    "    def __init__(self,\n",
    "                 X_train: pd.DataFrame,\n",
    "                 y_train: np.ndarray | np.recarray,\n",
    "                 X_pool: pd.DataFrame,\n",
    "                 y_pool: np.ndarray | np.recarray,\n",
    "                 ):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_pool = X_pool\n",
    "        self.y_pool = y_pool\n",
    "\n",
    "    def update_train_pool(self, X_queried: pd.DataFrame|pd.Series,\n",
    "                                y_queried: np.ndarray|np.recarray):\n",
    "        ''' given the selcted instance (X_queried, y_queried), drop it \n",
    "        from (X_pool, y_pool) and append it to (X_train, y_train) '''\n",
    "\n",
    "        self.X_train = pd.concat([self.X_train, X_queried])\n",
    "        print(self.y_train.shape)\n",
    "        print(y_queried.shape)\n",
    "        self.y_train = np.concatenate([self.y_train, np.array(y_queried)])\n",
    "        \n",
    "        # X_queried is now a pd.Series whose 'name' field (should) correspond to the original df index\n",
    "        self.X_pool = self.X_pool.drop([X_queried.name], axis=0)\n",
    "        self.y_pool = np.delete(self.y_pool, [y_queried.name], axis=0), \n",
    "        # self.y_pool = self.y_pool.drop([y_queried.name], axis=0)\n",
    "\n",
    "        return print(\"updated\")\n",
    "    \n",
    "    def random_sampling_query(self, random_state:Optional[int]=None) -> tuple[pd.DataFrame, pd.Series]:\n",
    "        random.seed(a=RANDSEED) #overrides random seed within random library\n",
    "    \n",
    "        #select random row, output as single raw df or index only or...\n",
    "        \n",
    "        # (random) select index based on position (iloc style)\n",
    "        query_list = list(range(self.X_pool.shape[0]))\n",
    "        query_index = random.choice(query_list)\n",
    "    \n",
    "        return self.X_pool.iloc[query_index], self.y_pool[query_index]\n",
    "    \n",
    "    def uncertainty_based_query(self, clf, populat_average: int|float) -> tuple[pd.DataFrame, pd.Series]:\n",
    "\n",
    "        proximity_to_average = clf.predict(self.X_pool) - populat_average # the smaller, the most uncertain (in a way)\n",
    "\n",
    "        return self.X_pool.loc[np.argmin(proximity_to_average)]\n",
    "\n",
    "    def variance_based_query(self, clf, uncertainty_measure) -> tuple[pd.DataFrame, pd.Series]:\n",
    "\n",
    "\n",
    "        return self.X_pool.loc[0]\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "rsf = RandomSurvivalForest(n_estimators=5, max_depth=5, random_state=0)\n",
    "rsf.fit(X_train, y_train)\n",
    "\n",
    "# in theory, loop along here:\n",
    "pop_average = rsf.predict(X_train).mean()\n",
    "\n",
    "ActiveLearn = SamplingQuery(X_train, y_train, X_pool, y_pool) #also y_train, y_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N* instances: (20, 9)\n",
      "performance: 0.49333333333333335\n",
      "age                     69.000\n",
      "pericardialeffusion      0.000\n",
      "fractionalshortening     0.150\n",
      "epss                    12.000\n",
      "lvdd                     5.390\n",
      "wallmotion-score        19.500\n",
      "wallmotion-index         1.625\n",
      "mult                     0.857\n",
      "group                    1.000\n",
      "Name: 40, dtype: float64 (False, 0.75)\n",
      "(20,)\n",
      "()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 0 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X_queried, y_queried \u001b[39m=\u001b[39m ActiveLearn\u001b[39m.\u001b[39mrandom_sampling_query(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(X_queried, y_queried)\n\u001b[1;32m----> 6\u001b[0m ActiveLearn\u001b[39m.\u001b[39;49mupdate_train_pool(X_queried, y_queried) \u001b[39m# df_queried should also privde the queried label\u001b[39;00m\n\u001b[0;32m      8\u001b[0m rsf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mN* instances:\u001b[39m\u001b[39m\"\u001b[39m, X_train\u001b[39m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[98], line 30\u001b[0m, in \u001b[0;36mSamplingQuery.update_train_pool\u001b[1;34m(self, X_queried, y_queried)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     29\u001b[0m \u001b[39mprint\u001b[39m(y_queried\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train, np\u001b[39m.\u001b[39;49marray(y_queried)])\n\u001b[0;32m     32\u001b[0m \u001b[39m# X_queried is now a pd.Series whose 'name' field (should) correspond to the original df index\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pool \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pool\u001b[39m.\u001b[39mdrop([X_queried\u001b[39m.\u001b[39mname], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 0 dimension(s)"
     ]
    }
   ],
   "source": [
    "rsf.fit(X_train, y_train)\n",
    "print(\"N* instances:\", X_train.shape)\n",
    "print(\"performance:\", rsf.score(X_test, y_test))\n",
    "X_queried, y_queried = ActiveLearn.random_sampling_query(random_state=0)\n",
    "print(X_queried, y_queried)\n",
    "ActiveLearn.update_train_pool(X_queried, y_queried) # df_queried should also privde the queried label\n",
    "\n",
    "rsf.fit(X_train, y_train)\n",
    "print(\"N* instances:\", X_train.shape)\n",
    "print(\"N* in pool:\", X_pool.shape)\n",
    "print(\"performance:\", rsf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31daf6a07ea00fcaae7570bc112f842ab0b1f34968999538ee820e4cfd237b67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
